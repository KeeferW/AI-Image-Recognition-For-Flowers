from PIL import Image
from matplotlib.pyplot import imshow as ish
from torch import nn
from torch import optim
from torchvision import datasets, transforms, models
import json

import argparse
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import torch
import argparse

parser = argparse.ArgumentParser()
parser.add_argument(type = str, dest = 'data_dir')
parser.add_argument('--save_dir', dest = 'save_dir', type = str, default='')
parser.add_argument('--arch', dest = 'arch', type = str, default = 'densenet161')
parser.add_argument('--learning_rate', dest = 'learning_rate', type = float, default = 0.002)
parser.add_argument('--hidden_units', dest = 'hidden_units', type = int, default = 1000)
parser.add_argument('--epochs', dest = 'epochs', type = int, default = 1)
parser.add_argument('--gpu', action = 'store_const', const = 'gpu')

args = parser.parse_args()

train_dir = args.data_dir + '/train'
valid_dir = args.data_dir + '/valid'
test_dir = args.data_dir + '/test'

train_transforms = transforms.Compose([transforms.RandomRotation(30), transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), 
                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
valid_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],  [0.229, 0.224, 0.225])])
test_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
 
train_dataset = datasets.ImageFolder(train_dir, transform = train_transforms)
valid_dataset = datasets.ImageFolder(valid_dir, transform = valid_transforms)
test_dataset = datasets.ImageFolder(train_dir, transform = test_transforms)

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle = True)
valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 32, shuffle = True)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if torch.cuda.is_available():
    if args.gpu != 'gpu':
        print('gpu is now disabled')
        device = 'cpu'
    if args.gpu == 'gpu':
        print('gpu is now enabled')
        device = 'cuda'
else:
    print('gpu not available')
    device = 'cpu'
units = args.hidden_units

if args.arch == 'densenet161':    
    model = models.densenet161(pretrained = True)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier = nn.Sequential(nn.Linear(2208, units), nn.ReLU(), nn.Dropout(0.2), nn.Linear(units, int(units/2)), nn.ReLU(), nn.Dropout(0.2),                                  
                                     nn.Linear(int(units / 2), 102), nn.LogSoftmax(dim = 1))
elif args.arch=="vgg16":
    model = models.vgg16(pretrained = True)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier = nn.Sequential(nn.Linear(25088, units), nn.ReLU(), nn.Dropout(0.2), nn.Linear(units, int(units / 2)), nn.ReLU(), nn.Dropout(0.2), nn.Linear(int(units / 2), 102), 
                                     nn.LogSoftmax(dim = 1))
criterion = nn.NLLLoss()
rate = rgs.learning_rate
opt = optim.Adam(model.classifier.parameters(), lr = rate)
model.to(device)
epochs = args.epochs
inc = 0
rLoss = 0

for epoch in range(epochs):
    for inputs, labels in train_dataloader:
        
        inc += 1
        inputs, labels = inputs.to(device), labels.to(device)
        opt.zero_grad()
        logps = model.forward(inputs)
        loss = criterion(logps, labels)
        loss.backward()
        opt.step()
        rLoss += loss.item()
       if inc % 5 == 0:
            tLoss = 0
            acc = 0
            model.eval()
            with torch.no_grad():
                for inputs, labels in valid_dataloader:
                    inputs, labels = inputs.to(device), labels.to(device)
                    log = model.forward(inputs)
                    bLoss = criterion(log, labels)
                    tLoss += bLoss.item()
                    ps = torch.exp(log)
                    top_p, top_class = ps.topk(1, dim = 1)
                    equals = top_class == labels.view(*top_class.shape)
                    acc += torch.mean(equals.type(torch.FloatTensor)).item()
                    
            print(f"Epoch {epoch + 1} / {epochs}.. " f"Train loss: {rLoss / 5:.3f}.. " f"Valid loss: {tLoss / len(valid_dataloader):.3f}.. "
                  f"Valid accuracy: {acc / len(valid_dataloader):.3f}")
            rLoss = 0
            model.train()
checkpoint = {'model.classifier':model.classifier, 'model.class_to_idx':train_dataset.class_to_idx, 'state_dict': model.state_dict(), 'epoch': epoch, 'optimizer_state_dict': optimizer.state_dict()}
if args.save_dir != "":
   torch.save(checkpoint, args.save_dir + "/some.pth")
